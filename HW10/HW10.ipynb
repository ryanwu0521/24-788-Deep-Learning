{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please complete the `NotImplemented` parts of the code cells and write your answers in the markdown cells designated for your response to any questions asked. The tag `# AUTOGRADED` (all caps, with a space after `#`) should be at the beginning of each autograded code cell, so make sure that you do not change that. You are also not allowed to import any new package other than the ones already imported. Doing so will prevent the autograder from grading your code.\n",
    "\n",
    "For the code submission, run the last cell in the notebook to create the submission zip file. If you are working in Colab, make sure to download and then upload a copy of the completed notebook itself to its working directory to be included in the zip file. Finally, submit the zip file to Gradescope.\n",
    "\n",
    "If you are running the notebook locally, make sure you have created a virtual environment (using `conda` for example) and have the proper packages installed. We are working with `python=3.10` and `torch>=2`.\n",
    "\n",
    "Files to be included in submission:\n",
    "\n",
    "- `HW10.ipynb`\n",
    "- `model_config.yaml`\n",
    "- `train_config.yaml`\n",
    "- `state_dict.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Union, Dict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# plotting:\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "# new package for loading data\n",
    "try:\n",
    "    import h5py\n",
    "except ImportError:\n",
    "    os.system('pip install h5py -qq')\n",
    "    import h5py\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from HW10_utils import Tracker\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    Device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    Device = 'mps'\n",
    "else:\n",
    "    Device = 'cpu'\n",
    "print(f'Device is {Device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scaled dot-product attention in `numpy` (20)\n",
    "\n",
    "First, you will implement the central operation of the transformer, i.e. the scaled_dot_product_attention using `numpy`. You will use the function from PyTorch to test your implementation, so you can easily test it before submission.\n",
    "\n",
    "To better understand what is happening, write the shape of each array as a comment.\n",
    "\n",
    "You may find `.swapaxes()` and `.tril()` useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOGRADED\n",
    "\n",
    "def softmax(z: np.ndarray):\n",
    "    \"\"\"\n",
    "    Applies softmax along the last dimension\n",
    "    \"\"\"\n",
    "    z -= np.max(z, axis=-1, keepdims=True)\n",
    "    exp = np.exp(z)\n",
    "    return exp / np.sum(exp, axis=-1, keepdims=True)\n",
    "\n",
    "\n",
    "def scaled_dot_product_attention(\n",
    "        query: np.ndarray, # (N, H, L, E)\n",
    "        key: np.ndarray, # (N, H, S, E)\n",
    "        value: np.ndarray, # (N, H, S, Ev)\n",
    "        attn_mask: Union[np.ndarray, None] = None, # (L, S) boolean mask\n",
    "        is_causal: bool = False,\n",
    "        ) -> np.ndarray: # (N, H, L, Ev)\n",
    "    \"\"\"\n",
    "    attn_mask is assumed to be boolean array of shape (L, S).\n",
    "    Where False, the corresponding attention element is omitted.\n",
    "    \"\"\"\n",
    "    \n",
    "    # perform the dot product between query and key\n",
    "    NotImplemented\n",
    "\n",
    "    # where attn_mask is False, set the attention values to -np.inf\n",
    "    if attn_mask is not None:\n",
    "        NotImplemented\n",
    "\n",
    "    # if causal, set the upper triangular part to -np.inf\n",
    "    if is_causal:\n",
    "        assert attn_mask is None, 'Cannot use both causal and attn_mask'\n",
    "        # create a causal mask and apply it similarly to how the attn_mask was applied\n",
    "        NotImplemented\n",
    "\n",
    "    # scale the attention values by square root of E\n",
    "    NotImplemented\n",
    "\n",
    "    # apply softmax to the last dimension\n",
    "    NotImplemented\n",
    "\n",
    "    # multiply attention with the value\n",
    "    # return the result\n",
    "    return NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HW10_utils import test_sdpa\n",
    "\n",
    "test_sdpa(scaled_dot_product_attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multihead Attention in `numpy` (20)\n",
    "\n",
    "Now that you have implemented the scaled dot-product attention, you can implement the forward pass of a multihead attention layer using `numpy`. You may find `.swapaxes()` and `.reshape()` useful. Also, remember that the mask is treated in the opposite way now, so you should reverse it when passing it to your numpy `scaled_dot_product_attention` if it is not `None`. \n",
    "\n",
    "Note: remember that for `nn.MultiheadAttention` from PyTorch, you still need to pass the `attn_mask` for a causal attention, and `is_causal` only acts as a hint to the module about the `attn_mask`, which you do need to provide explicitly. Therefore, the numpy function you are going to implement does not have that argument, and you need to define a causal mask if you want it to perform a causal attention. You have to do the same thing when using the forward pass of `nn.MultiheadAttention`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOGRADED\n",
    "\n",
    "def MultiheadAttention(\n",
    "        query_target: np.ndarray, # (N, L, E)\n",
    "        key_source: np.ndarray, # (N, S, kdim)\n",
    "        value_source: np.ndarray, # (N, S, vdim)\n",
    "        num_heads: int,\n",
    "        params: Dict[str, np.ndarray], # dict of weights\n",
    "        attn_mask: Union[np.ndarray, None] = None, # (L, S) boolean mask\n",
    "        ) -> np.ndarray: # (N, L, E)\n",
    "    \"\"\"\n",
    "    attn_mask is assumed to be boolean array of shape (L, S).\n",
    "    Where True, the corresponding attention element is omitted.\n",
    "\n",
    "    params: dictionary containing the following keys\n",
    "        Wq: weight matrix of shape (E, E)\n",
    "        Wk: weight matrix of shape (kdim, E)\n",
    "        Wv: weight matrix of shape (vdim, E)\n",
    "        Wo: weight matrix of shape (E, E)\n",
    "    \"\"\"\n",
    "    assert query_target.shape[-1] % num_heads == 0, 'Dimension should be divisible by nhead'\n",
    "\n",
    "    # You may find these useful to reshape the tensors\n",
    "    N, L, E = query_target.shape\n",
    "    N, S, E = key_source.shape\n",
    "\n",
    "    # compute the query, key, and value projections\n",
    "    NotImplemented\n",
    "\n",
    "    # reshape the arrays to split the feature dimension into num_heads groups (heads)\n",
    "    # then, order the axes properly for the scaled_dot_product_attention call\n",
    "    # so you can pass them to scaled_dot_product_attention\n",
    "    NotImplemented\n",
    "\n",
    "    # execute scaled dot product attention with your function from before\n",
    "    NotImplemented\n",
    "\n",
    "    # merge the heads back together\n",
    "    NotImplemented\n",
    "\n",
    "    # apply the final linear transformation\n",
    "    NotImplemented\n",
    "\n",
    "    return NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HW10_utils import test_mha\n",
    "\n",
    "test_mha(MultiheadAttention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a transformer to simulate a 1D PDE (60)\n",
    "\n",
    "In this section, you will umplement a decoder-only transformer to predict the future time-steps of a system governed by a Partial Differential Equation (PDE). The dataset class is already provvided for you and you can visualize and investigate it using the interactive visualizer class. Your tasks are the following:\n",
    "\n",
    "- Implement the positional encoding from the original transformer paper, to be added to the data at the beginning of the model's forward pass (10)\n",
    "\n",
    "- Implement the forward pass of the decoder-only transformer layer. You will find further details in the relevant section (15)\n",
    "\n",
    "- Implement an autoregressive method to predict future steps for the inference/evaluation stage (15)\n",
    "\n",
    "- Find and train a model to achieve desirable error (10)\n",
    "\n",
    "- Conclude the effect of the hyperparameters (10)\n",
    "\n",
    "\n",
    "\n",
    "## Dataset \n",
    "First, we have provided you with a PDE dataset. The dataset contains the solution of the Burger's equation over time, on a discretized grid over time and space. The Burger's equation is defined as the following:\n",
    "$$\n",
    "\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x} = \\nu \\frac{\\partial^2 u}{\\partial x^2}\n",
    "$$\n",
    "\n",
    "where $\\nu$ is the kinematic viscousity. In our dataset, the spatial domain is under periodic boundary conditions, and each sample trajectory starts from a random initail condition. The domains and the parameters of the PDE are as follows:\n",
    "$$\n",
    "x \\in [0, 1) \\quad t \\in [0, 1] \\quad \\nu = 0.01\n",
    "$$\n",
    "and the spatial and temporal domain are discretized into 128 and 51 points respectively. The original dataset was provided by [this paper](https://arxiv.org/abs/2010.08895), and we have prepared a downsampled version of it for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Burgers_Dataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_path: str = 'data/Train_Burgers_v1e-2_N1792_T1_tr50_X1_xr128.hdf5',\n",
    "            device: str = 'cpu',\n",
    "            ):\n",
    "        super().__init__()\n",
    "\n",
    "        # load the data\n",
    "        with h5py.File(data_path, 'r') as file:\n",
    "            self.u = torch.tensor(file['u'][:], dtype=torch.float32, device=device) # (N, rt, rx)\n",
    "            self.t = torch.tensor(file['t-coordinate'][:], dtype=torch.float32, device=device)\n",
    "            self.x = torch.tensor(file['x-coordinate'][:], dtype=torch.float32, device=device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.u)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.u[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_burger(\n",
    "    dataset: Burgers_Dataset,\n",
    "    idx: int, \n",
    "    # For comparing model output:\n",
    "    model: Union[None, nn.Module] = None,\n",
    "    loss_fn: callable = F.mse_loss,\n",
    "    n_starting_steps: int = 10,\n",
    "    ):\n",
    "    fig, ax = plt.subplots(\n",
    "        1, 1 if model is None else 3,\n",
    "        figsize = (4 if model is None else 12, 4),\n",
    "        sharex = True, sharey = True,\n",
    "        )\n",
    "\n",
    "    if model is not None:\n",
    "        model.eval().cpu()\n",
    "        ax, ax_model, ax_diff = ax\n",
    "\n",
    "    t, x = dataset.t, dataset.x\n",
    "    u = dataset[idx:idx+1]\n",
    "\n",
    "    # using pcolormesh to plot the data and sace the returned object to update with the widget\n",
    "    true_im = ax.pcolormesh(\n",
    "        x, t, u[0].cpu().numpy(), \n",
    "        cmap='seismic', vmin=-1, vmax=1)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('t')\n",
    "    ax.set_title(f'data index: {idx}')\n",
    "\n",
    "\n",
    "    fig.colorbar(true_im, ax=ax)\n",
    "\n",
    "    if model is not None:\n",
    "\n",
    "        model_input = u[:, :n_starting_steps, :]\n",
    "        steps = u.shape[1] - n_starting_steps\n",
    "        with torch.inference_mode():\n",
    "            model_output = model.predict(model_input, steps=steps)\n",
    "            loss = loss_fn(model_output, u[:, n_starting_steps:, :]).item()\n",
    "            pred_u = torch.cat([model_input, model_output], dim=1)\n",
    "            diff = pred_u - u\n",
    "\n",
    "        pred_im = ax_model.pcolormesh(\n",
    "            x, t, pred_u[0].cpu().numpy(), \n",
    "            cmap='seismic', vmin=-1, vmax=1)\n",
    "        ax_model.set_xlabel('x')\n",
    "        ax_model.set_ylabel('t')\n",
    "        ax_model.set_title('Model Prediction')\n",
    "        fig.colorbar(pred_im, ax=ax_model)\n",
    "\n",
    "        diff_im = ax_diff.pcolormesh(\n",
    "            x, t, diff[0].cpu().numpy(), \n",
    "            cmap='seismic', vmin=-1, vmax=1)\n",
    "        ax_diff.set_xlabel('x')\n",
    "        ax_diff.set_ylabel('t')\n",
    "        ax_diff.set_title('Difference')\n",
    "        fig.colorbar(diff_im, ax=ax_diff)\n",
    "        ax_diff.set_title(f'Difference, loss: {loss:.4f}')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Burgers_Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = viz_burger(train_dataset, idx=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding (10)\n",
    "\n",
    "Implement the positional encoding from the paper, to be added to the input of the transformer. According to the paper:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "In this work, we use sine and cosine functions of different frequencies:\n",
    "$$\n",
    "PE_{(pos, 2i)} = \\sin \\left( pos / 10000^{2i / d_{\\text{model}}} \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "PE_{(pos, 2i+1)} = \\cos \\left( pos / 10000^{2i / d_{\\text{model}}} \\right)\n",
    "$$\n",
    "where $pos$ is the position and $i$ is the dimension. That is, each dimension of the positional encoding corresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000·2π. We chose this function because we hypothesized it would allow the model to easily learn to attend by relative positions, since for any fixed offset $k$, $PE_{pos+k}$ can be represented as a linear function of $PE_{pos}$.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOGRADED\n",
    "\n",
    "def positional_encoding(\n",
    "        embed_dim: int, # d_model in the formula\n",
    "        max_len: int = 10000, # maximum length of the sequence (10000 in the formula)\n",
    "        ) -> torch.FloatTensor: # (max_len, embed_dim)\n",
    "    \n",
    "    pe = torch.zeros(max_len, embed_dim, dtype=torch.float32)\n",
    "\n",
    "    # create a tensor representing all i's and pos's using torch.arange\n",
    "    # make sure the shapes are right so they can be broadcasted correctly.\n",
    "\n",
    "    # shape (embed_dim//2,)\n",
    "    # ranges from 0 to embed_dim//2\n",
    "    i = NotImplemented\n",
    "\n",
    "    # shape (max_len, 1)\n",
    "    pos = NotImplemented\n",
    "\n",
    "    # calculate the angles (the argument to sine or cosine)\n",
    "    # shape (max_len, embed_dim//2)\n",
    "    angles = NotImplemented\n",
    "\n",
    "    # fill in the even indices with sine and odd indices with cosine\n",
    "    NotImplemented\n",
    "\n",
    "    return pe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the `forward` and `predict` methods (40)\n",
    "\n",
    "Now you have to fill in the `forward` method of the TransformerLayer class. Remember that this is a decoder-only transformer, meaning that there is no cross-attention to some memory, and the self-attention is causal. You will need to provide the proper mask for a correct implementation. Refer to [this paper](https://arxiv.org/pdf/2002.04745) for hints to implement `forward` based on `self.norm_first`.\n",
    "\n",
    "Next, you will implement the `predict` method which autoregressively predicts new steps. We start with the first 10 frames of the trajectory. Similar to the RNN assignment, the output sequence is supposed to be the input sequence shifted for one time-step. Therefore, each forward pass of the model will give you a new time-step at the end of its output. Your model input will therefore gradually increase in length with every new step that is predicted and appendded to it for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOGRADED\n",
    "\n",
    "def FFN(dim: int = 128, bias: bool = False) -> nn.Module:\n",
    "    \"\"\"\n",
    "    A simple feedforward network with GELU activation\n",
    "    Used in the TransformerLayer\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(dim, dim*2, bias=bias),\n",
    "        nn.GELU(),\n",
    "        nn.Linear(dim*2, dim, bias=bias),\n",
    "        )\n",
    "\n",
    "\n",
    "def causal_attn_mask(\n",
    "        x: torch.Tensor, # (B, nt, embed_dim)\n",
    "        ) -> torch.BoolTensor: # (nt, nt)\n",
    "    \"\"\"\n",
    "    where True, attention is omitted!\n",
    "    \"\"\"\n",
    "    nt = x.shape[1]\n",
    "\n",
    "    # return a causal mask\n",
    "\n",
    "    return NotImplemented\n",
    "\n",
    "\n",
    "class TransformerLayer(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            embed_dim: int = 128,\n",
    "            num_heads: int = 4,\n",
    "            norm_first: bool = False,\n",
    "            bias: bool = False,\n",
    "            ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.norm_first = norm_first\n",
    "\n",
    "        self.attn_ln = nn.LayerNorm(embed_dim)\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            embed_dim = embed_dim,\n",
    "            num_heads = num_heads,\n",
    "            bias = bias,\n",
    "            batch_first = True,\n",
    "            )\n",
    "        \n",
    "        self.ffn_ln = nn.LayerNorm(embed_dim)\n",
    "        self.ffn = FFN(embed_dim, bias=bias)\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            x: torch.FloatTensor, # (B, nt, embed_dim)\n",
    "            ) -> torch.FloatTensor: # (B, nt, embed_dim)\n",
    "        \"\"\"\n",
    "        Implement the forward pass of the transformer decoder layer without the cross-attention.\n",
    "        It is similar to the typical Transformer Encoder Layer, but with a causal self-attention!\n",
    "        \"\"\"\n",
    "\n",
    "        NotImplemented\n",
    "\n",
    "        return x\n",
    "        \n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_layers: int = 6,\n",
    "            embed_dim: int = 128,\n",
    "            num_heads: int = 4,\n",
    "            norm_first: bool = False,\n",
    "            bias: bool = False,\n",
    "            ):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_in = nn.Sequential(\n",
    "            nn.Linear(128, embed_dim, bias=bias),\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            )\n",
    "\n",
    "        self.layers = nn.Sequential(*[\n",
    "            TransformerLayer(\n",
    "                embed_dim = embed_dim,\n",
    "                num_heads = num_heads,\n",
    "                norm_first = norm_first,\n",
    "                bias = bias,\n",
    "                )\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "        self.embed_out = nn.Linear(embed_dim, 128, bias=bias)\n",
    "\n",
    "        self.register_buffer(\n",
    "            'pos_enc',\n",
    "            positional_encoding(\n",
    "                max_len = 51,\n",
    "                embed_dim = embed_dim,\n",
    "            ),\n",
    "            )\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            x: torch.FloatTensor, # (B, nt, 128)\n",
    "            ) -> torch.FloatTensor: # (B, nt, 128)\n",
    "        \"\"\"\n",
    "        Tries to learn the shifted sequence for one-step.\n",
    "        Will be used autoregressively in the predict method below.\n",
    "        \"\"\"\n",
    "        # embed_in\n",
    "        x = self.embed_in(x)\n",
    "\n",
    "        # add positional encoding\n",
    "        # slice self.pos_enc to get the time-steps corresponding to the input x\n",
    "        # you can assume that the start time is 0\n",
    "        x = x + self.pos_enc[:x.shape[1]]\n",
    "        \n",
    "        # transformer layers\n",
    "        x = self.layers(x)\n",
    "\n",
    "        # embed_out\n",
    "        x = self.embed_out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def predict(\n",
    "            self,\n",
    "            x: torch.FloatTensor, # (B, n_starting_steps, 128)\n",
    "            steps: int, # number of steps to predict\n",
    "            ) -> torch.FloatTensor: # (B, steps, 128)\n",
    "        \"\"\"\n",
    "        This is the function that is used in inference/evaluation.\n",
    "        Since we would not have the whole sequence, we will predict the next step autoregressively.\n",
    "        This means that at each step, we will predict the next step and append it to the input sequence.\n",
    "        Therefore, the input to the model at each step will be the concatenation of the previous input and the new predicted step.\n",
    "        \"\"\"\n",
    "\n",
    "        output = []\n",
    "\n",
    "        for t in range(steps):\n",
    "\n",
    "            # a forward pass of the transformer to shift the sequence by one time-step\n",
    "            NotImplemented\n",
    "\n",
    "            # append the new predicted time-step to the output\n",
    "            NotImplemented\n",
    "\n",
    "            # create the input for the next step by concatenating the current input\n",
    "            # with the new predicted time-step.\n",
    "            NotImplemented\n",
    "\n",
    "        # stack or concatenate the predicted steps in the output list and return the tensor\n",
    "        return NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "As yet another reminder, we can use the whole sequence during training. However, we do not have access to the full trajectory in inference (evaluation) stage. Therefore, we start from several initial steps, and autoregressively predict future steps. Take a close look at the `eval_epoch` function to see how it works. This will be the final metric used to evaluate your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rL2Loss(\n",
    "        pred: torch.FloatTensor, # (B, nt, nx)\n",
    "        target: torch.FloatTensor, # (B, nt, nx)\n",
    "        norm_dim = (1, 2)\n",
    "        ) -> torch.FloatTensor: # ()\n",
    "    \"\"\"\n",
    "    relative L2 loss. A common loss used for PDE data.\n",
    "    \"\"\"\n",
    "    error = pred - target\n",
    "    error_norm = error.norm(dim=norm_dim, p=2)\n",
    "    target_norm = target.norm(dim=norm_dim, p=2)\n",
    "    return (error_norm / target_norm).mean()\n",
    "\n",
    "\n",
    "@torch.enable_grad()\n",
    "def train_epoch(\n",
    "        model: Model,\n",
    "        train_loader: DataLoader,\n",
    "        optimizer: optim.Optimizer,\n",
    "        loss_fn: callable = rL2Loss,\n",
    "        device = Device,\n",
    "        ):\n",
    "    model.train().to(device)\n",
    "    for x in train_loader:\n",
    "        x = x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        model_input = x[:, :-1] # remove the last step\n",
    "        target = x[:, 1:] # remove the first step\n",
    "        # target is the model_input shifted by one step\n",
    "        output = model(model_input)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def eval_epoch(\n",
    "        model: Model,\n",
    "        eval_loader: DataLoader,\n",
    "        loss_fn: callable = rL2Loss,\n",
    "        autoregressive: bool = True,\n",
    "        n_starting_steps: int = 10, # for autoregressive mode\n",
    "        device = Device,\n",
    "        ):\n",
    "    model.eval().to(device)\n",
    "    total_loss = 0\n",
    "    for x in eval_loader:\n",
    "        b = len(x)\n",
    "        x = x.to(device)\n",
    "\n",
    "        if autoregressive:\n",
    "            model_input = x[:, :n_starting_steps]\n",
    "            target = x[:, n_starting_steps:]\n",
    "            output = model.predict(model_input, steps=target.shape[1])\n",
    "        else:\n",
    "            model_input = x[:, :-1]\n",
    "            target = x[:, 1:]\n",
    "            output = model(model_input)\n",
    "\n",
    "        loss = loss_fn(output, target)\n",
    "        total_loss += loss.item() * b\n",
    "    return total_loss / len(eval_loader.dataset)\n",
    "\n",
    "\n",
    "def train(\n",
    "        model: Model,\n",
    "        train_dataset: Dataset,\n",
    "        device = Device,\n",
    "        plot_freq: int = 1,\n",
    "\n",
    "        optimizer_name: str = 'Adam',\n",
    "        optimizer_config: dict = dict(),\n",
    "        lr_scheduler_name: Union[str, None] = None,\n",
    "        lr_scheduler_config: dict = dict(),\n",
    "\n",
    "        n_epochs: int = 50,\n",
    "        batch_size: int = 64,\n",
    "        ):\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = rL2Loss\n",
    "\n",
    "    tracker = Tracker(n_epochs=n_epochs, plot_freq=plot_freq)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    optimizer: optim.Optimizer = optim.__getattribute__(optimizer_name)(model.parameters(), **optimizer_config)\n",
    "    if lr_scheduler_name is not None:\n",
    "        lr_scheduler: optim.lr_scheduler.LRScheduler = optim.lr_scheduler.__getattribute__(lr_scheduler_name)(optimizer, **lr_scheduler_config)\n",
    "\n",
    "    epoch_pbar = tqdm(range(n_epochs), desc='Epochs', unit='epoch', leave=True)\n",
    "\n",
    "    for epoch in epoch_pbar:\n",
    "\n",
    "        train_epoch(\n",
    "            model = model,\n",
    "            train_loader = train_loader,\n",
    "            optimizer = optimizer,\n",
    "            loss_fn = loss_fn,\n",
    "            device = device,\n",
    "            )\n",
    "        \n",
    "        eval_loss = eval_epoch(\n",
    "            model = model,\n",
    "            eval_loader = train_loader,\n",
    "            loss_fn = loss_fn,\n",
    "            autoregressive = False,\n",
    "            device = device,\n",
    "            )\n",
    "        \n",
    "        eval_loss_AR = eval_epoch(\n",
    "            model = model,\n",
    "            eval_loader = train_loader,\n",
    "            loss_fn = loss_fn,\n",
    "            autoregressive = True,\n",
    "            device = device,\n",
    "            )\n",
    "\n",
    "        if lr_scheduler_name == 'ReduceLROnPlateau':\n",
    "            lr_scheduler.step(eval_loss)\n",
    "        elif lr_scheduler_name is not None:\n",
    "            lr_scheduler.step()\n",
    "        \n",
    "        epoch_pbar.set_postfix_str(f'loss: {eval_loss:.4f}, AR loss: {eval_loss_AR:.4f}')\n",
    "        tracker.update(eval_loss, eval_loss_AR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and train a good model (10)\n",
    "\n",
    "You should achieve a good evaluation loss on the test dataset, which is calculated by the autograder. You can expect the loss to be similar to that of the training dataset. To save time, we provided most of the hyperparameters here, so you can only explore the ones specified by the comments. Be patient with the training, as the autoregressive loss is much larger and more unstable than the loss used in training. You should expect to get low enough loss by 50 epochs. You can interrupt the training early.\n",
    "\n",
    "- $\\text{test loss} \\leq 0.10$: 10 points\n",
    "\n",
    "- $\\text{test loss} \\leq 0.20$: 5 points\n",
    "\n",
    "- $\\text{test loss} > 0.20$: 0 points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Search for hyperparameters.\n",
    "\"\"\"\n",
    "\n",
    "model_config = dict(\n",
    "    n_layers = 4,\n",
    "    embed_dim = 128,\n",
    "    num_heads = 4,\n",
    "    norm_first = True, # try  changing this\n",
    "    bias = False, # try changing this\n",
    "    )\n",
    "\n",
    "train_config = dict(\n",
    "    optimizer_name = 'AdamW',\n",
    "    optimizer_config = dict(),\n",
    "    lr_scheduler_name = 'ReduceLROnPlateau',\n",
    "    lr_scheduler_config = dict(factor=0.5, patience=3),\n",
    "\n",
    "    n_epochs = 50,\n",
    "    batch_size = 128,\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_dataset = Burgers_Dataset(device=Device)\n",
    "    model = Model(**model_config)\n",
    "    train(\n",
    "        model = model, \n",
    "        train_dataset = train_dataset, \n",
    "        device = Device,\n",
    "        plot_freq = 1,\n",
    "        **train_config,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_burger(\n",
    "    dataset = train_dataset, \n",
    "    idx = 4, # You can visualize different samples\n",
    "    model = model, \n",
    "    loss_fn = rL2Loss, \n",
    "    n_starting_steps = 10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zip files for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HW10_utils import save_yaml, load_yaml, zip_files\n",
    "\n",
    "\n",
    "save_yaml(model_config, 'model_config.yaml')\n",
    "save_yaml(train_config, 'train_config.yaml')\n",
    "torch.save(model.cpu().state_dict(), 'state_dict.pt')\n",
    "\n",
    "# try loading the model\n",
    "model = Model(**load_yaml('model_config.yaml')).cpu()\n",
    "model.load_state_dict(torch.load('state_dict.pt', map_location='cpu'))\n",
    "print(\"Model can be loaded successfully!\")\n",
    "\n",
    "submission_files = ['HW10.ipynb', 'model_config.yaml', 'train_config.yaml', 'state_dict.pt']\n",
    "zip_files('HW10_submission.zip', submission_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_TA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
